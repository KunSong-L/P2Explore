{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "model_name_list =  [\"fpunet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = 128\n",
    "batch_size = 64\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "\n",
    "from utils.FPUNet import FPUNet\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    feature_scale = 2\n",
    "\n",
    "    if model_name == \"fpunet\":\n",
    "        model = FPUNet(in_channels=3, n_classes=3, feature_scale=feature_scale).to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# net = get_model(\"fpunet\")\n",
    "\n",
    "# from torchinfo import summary  \n",
    "# print(summary(net, (1,3,fig_size,fig_size)))\n",
    "\n",
    "# test_input = torch.tensor(np.random.rand(1,3,fig_size,fig_size),dtype=torch.float32).to(device)\n",
    "# with torch.no_grad():\n",
    "#     net.eval()\n",
    "#     out = net(test_input)\n",
    "#     print(out.shape)\n",
    "#     print(out[0,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"dataset/gen_data\"\n",
    "\n",
    "train_data = np.load(f'./{file_name}/train_data.npz', allow_pickle=True)\n",
    "val_data = np.load(f'./{file_name}/val_data.npz', allow_pickle=True)\n",
    "test_data = np.load(f'./{file_name}/test_data.npz', allow_pickle=True)\n",
    "\n",
    "input_train = train_data[\"train_list\"]\n",
    "out_train = train_data[\"label_list\"]\n",
    "\n",
    "input_val = val_data[\"train_list\"]\n",
    "out_val = val_data[\"label_list\"]\n",
    "\n",
    "input_test = test_data[\"train_list\"]\n",
    "out_test = test_data[\"label_list\"]\n",
    "\n",
    "#modify the data: from dim 1 to dim 3\n",
    "#each dim represent: free, occupied, unknown\n",
    "def modify_data(data):\n",
    "    #free, occupied, unknown\n",
    "    res = torch.zeros((data.shape[0],3,data.shape[2],data.shape[3]))\n",
    "    for i in range(data.shape[0]):\n",
    "        res[i,0] = data[i] > 200\n",
    "        res[i,1] = data[i] < 10\n",
    "        #> 90 and < 110\n",
    "        res[i, 2] = (data[i] > 90) & (data[i] < 110)\n",
    "        # res[i,2] = data[i] > 90 \n",
    "    return res\n",
    "\n",
    "input_train = modify_data(torch.from_numpy(input_train.reshape((-1,1,fig_size,fig_size))))\n",
    "out_train = modify_data(torch.from_numpy(out_train.reshape((-1,1,fig_size,fig_size))))\n",
    "\n",
    "input_val = modify_data(torch.from_numpy(input_val.reshape((-1,1,fig_size,fig_size))))\n",
    "out_val = modify_data(torch.from_numpy(out_val.reshape((-1,1,fig_size,fig_size))))\n",
    "\n",
    "input_test = modify_data(torch.from_numpy(input_test.reshape((-1,1,fig_size,fig_size))))\n",
    "out_test = modify_data(torch.from_numpy(out_test.reshape((-1,1,fig_size,fig_size))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_img(img):\n",
    "    return np.transpose(img,(1,2,0))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(trans_img(input_train[10]))\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(trans_img(out_train[10]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "#use the nosiy observations as input and perform the prediction\n",
    "train_dataset = data_utils.TensorDataset(input_train, out_train)\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#测试\n",
    "test_dataset = data_utils.TensorDataset(input_test, out_test)\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#验证\n",
    "val_dataset = data_utils.TensorDataset(input_val, out_val)\n",
    "val_loader = data_utils.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def image_norm(x):\n",
    "    return x*2.0/255 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "obs_weight = 0.6\n",
    "class_weights = torch.tensor([0.2,obs_weight,0.2])  # free occupied unknown\n",
    "num_epochs = 400\n",
    "\n",
    "for now_model in model_name_list:\n",
    "    #clear cuda cache\n",
    "    torch.cuda.empty_cache()\n",
    "    net = get_model(now_model)\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    loss_func = loss_func.to(device) \n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0.0001, T_max=10, last_epoch=-1)\n",
    "\n",
    "    \n",
    "    net = net.to(device)\n",
    "\n",
    "    min_loss_train = 1e9\n",
    "    min_loss_val = 1e9\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    min_val_epoch = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        \n",
    "        net.train()  \n",
    "        epoch_loss = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()  \n",
    "            inputs,labels = inputs.to(torch.float32).to(device),labels.to(torch.float32).to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_loss /= len(train_loader)\n",
    "\n",
    "        train_loss_list.append(epoch_loss) \n",
    "        if epoch % 50 == 0:\n",
    "            #save\n",
    "            torch.save(net.state_dict(), f\"./trained_model/last_{now_model}_{fig_size}_{epoch}.pth\")\n",
    "        \n",
    "        net.eval()  \n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for i, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs,labels = inputs.to(torch.float32).to(device),labels.to(torch.float32).to(device)\n",
    "\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = loss_func(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "        # print(f\"epoch: {epoch}, train_loss: {epoch_loss}, val_loss: {val_loss}\")\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        if val_loss < min_loss_val:\n",
    "            torch.save(net.state_dict(), f\"./trained_model/best_{now_model}_{fig_size}_{num_epochs}.pth\")\n",
    "            min_loss_val = val_loss\n",
    "            min_val_epoch = epoch\n",
    "    \n",
    "    torch.save(net.state_dict(), f\"./trained_model/last_{now_model}_{fig_size}_{num_epochs}.pth\")\n",
    "    print(f\"{now_model}, min_val_epoch:{min_val_epoch} min_loss_val:{min_loss_val}\")\n",
    "\n",
    "    x = np.arange(len(train_loss_list))\n",
    "\n",
    "    plt.plot(x, train_loss_list, label='Train Loss')\n",
    "    plt.plot(x, val_loss_list, label='Validation Loss')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def plot_images(ax,images):\n",
    "    if images.shape[0] == 1:\n",
    "        images = images[0]\n",
    "    ax.imshow(images,cmap=\"gray\")\n",
    "def probability_to_label(origin):\n",
    "    #origin: (N,3,128,128)\n",
    "    #return: (N,128,128)\n",
    "    res = torch.ones(origin.shape[0],origin.shape[2],origin.shape[3],dtype=torch.int64)\n",
    "    for i in range(origin.shape[0]):\n",
    "        index_mat = torch.argmax(origin[i],dim=0)\n",
    "        res[i] = index_mat\n",
    "        res[i][index_mat == 0] = 255\n",
    "        res[i][index_mat == 1] = 0\n",
    "        res[i][index_mat == 2] = 100\n",
    "    \n",
    "    return res\n",
    "\n",
    "def evaluate_result(gt, predict):\n",
    "    # gt: (N, 128, 128)\n",
    "    # predict: (N, 128, 128)\n",
    "    \n",
    "    N, H, W = gt.shape\n",
    "    \n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        tp = np.sum((gt[i] == 0) & (predict[i] == 0))\n",
    "        fn = np.sum((gt[i] == 0) & (predict[i] != 0))\n",
    "        fp = np.sum((gt[i] != 0) & (predict[i] == 0))\n",
    "        \n",
    "        total_tp += tp\n",
    "        total_fn += fn\n",
    "        total_fp += fp\n",
    "    \n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 Score as a combined metric\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return recall,precision,f1_score\n",
    "\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "for now_model in model_name_list:\n",
    "    print(f\"now_model: {now_model}\")\n",
    "\n",
    "    best_net = get_model(now_model)\n",
    "    #Note that the training process is not so stable, you can also try the checkpoint of the last epoch\n",
    "    state_dict = torch.load(f\"./trained_model/best_{now_model}_{fig_size}_{num_epochs}.pth\",weights_only=True)\n",
    "    \n",
    "    best_net.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    best_net = best_net.to(device)\n",
    "\n",
    "    best_net.eval() \n",
    "    input_list = []\n",
    "    gt_img_list = []\n",
    "    predict_img_list = []\n",
    "\n",
    "    for test_image,gt_img in test_loader:\n",
    "\n",
    "\n",
    "        test_image = test_image.reshape(-1,n_channels,fig_size,fig_size).to(torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_img = best_net(test_image)\n",
    "\n",
    "        for now_gt_img,now_pre, now_input in zip(probability_to_label(gt_img),probability_to_label(predicted_img),probability_to_label(test_image)):\n",
    "            gt_img_list.append(now_gt_img.numpy().reshape(fig_size,fig_size))\n",
    "            predict_img_list.append(now_pre.cpu().numpy().reshape(fig_size,fig_size))\n",
    "            input_list.append(now_input.cpu().numpy().reshape(fig_size,fig_size))   \n",
    "        \n",
    "    input_list = np.array(input_list)\n",
    "    gt_img_list = np.array(gt_img_list)\n",
    "    predict_img_list = np.array(predict_img_list)\n",
    "\n",
    "    recall,precision,f1_score = evaluate_result(gt_img_list, predict_img_list)\n",
    "    print(f\"{now_model} test recall: {recall}, precision: {precision}, f1_score: {f1_score}\")\n",
    "\n",
    "    # print(f\"{now_model} test loss: {current_loss}\")\n",
    "\n",
    "    view_index = [1,10,100]\n",
    "    fig_list = [input_list[view_index],gt_img_list[view_index],predict_img_list[view_index]]\n",
    "    title_list = ['Input Label','GT Label','Predicted']\n",
    "    eval_num = len(view_index)\n",
    "    fig, axes = plt.subplots(eval_num, len(fig_list), figsize=(len(fig_list) *2.4, eval_num * 2.5))\n",
    "    for i,ax_list in enumerate(axes):\n",
    "        for j in range(len(fig_list)):\n",
    "\n",
    "            current_ax = ax_list[j]\n",
    "            current_img = fig_list[j][i]\n",
    "            current_title = title_list[j]\n",
    "            plot_images(current_ax,current_img)\n",
    "            current_ax.set_title(current_title)\n",
    "            current_ax.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
